{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install zip unzip\n",
    "!git clone --branch updt https://github.com/TheLastBen/diffusers\n",
    "!pip install -q diffusers\n",
    "!pip install -U -r diffusers/examples/dreambooth/requirements.txt\n",
    "!pip install -U accelerate\n",
    "!pip install -U gdown\n",
    "!pip install -U wget\n",
    "!pip install -U deepspeed\n",
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Inputs for the training:\n",
    "- The name of the model from HuggingFace, Models I like to use:\n",
    "    - runwayml/stable-diffusion-v1-5 \n",
    "    - nitrosocke/Arcane-Diffusion\n",
    "    - nitrosocke/mo-di-diffusion \n",
    "    - nitrosocke/spider-verse-diffusion\n",
    "    - nitrosocke/Ghibli-Diffusion\n",
    "    - nitrosocke/archer-diffusion\n",
    "    - nitrosocke/classic-anim-diffusion\n",
    "    - DGSpitzer/Cyberpunk-Anime-Diffusion\n",
    "    - dallinmackay/Tron-Legacy-diffusion\n",
    "    - Envvi/Inkpunk-Diffusion\n",
    "    - dallinmackay/Van-Gogh-diffusion\n",
    "    - ogkalu/Comic-Diffusion\n",
    "- The class name that your images will belong to:\n",
    "    - person\n",
    "    - man\n",
    "    - woman\n",
    "- The unique token to identify your character in the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '' #nitrosocke/Arcane-Diffusion - nitrosocke/mo-di-diffusion\n",
    "CLASS_NAME = 'person' # options: person, man, woman\n",
    "INSTANCE_TOKEN = '' # token that will be used in the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import wget\n",
    "\n",
    "class_path = Path('./regularization_images')\n",
    "if not class_path.exists():\n",
    "    class_path.mkdir(parents=True)\n",
    "\n",
    "output_path = Path('./output').joinpath(INSTANCE_TOKEN).joinpath(MODEL_NAME)\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)\n",
    "\n",
    "CLASS_DIR = class_path.as_posix()\n",
    "OUTPUT_DIR = output_path.as_posix()\n",
    "\n",
    "if CLASS_NAME == 'person':\n",
    "    data_file = 'person_v1-5_mse_vae_ddim50_cfg7_n2115'\n",
    "elif CLASS_NAME == 'man':\n",
    "    data_file = 'guy_v1-5_mse_vae_ddim50_cfg7_n4820'\n",
    "elif CLASS_NAME == 'woman':\n",
    "    data_file = 'woman_v1-5_mse_vae_ddim50_cfg7_n4420'\n",
    "\n",
    "url = f'https://huggingface.co/datasets/ProGamerGov/StableDiffusion-v1-5-Regularization-Images/resolve/main/{data_file}.zip'\n",
    "\n",
    "file = wget.download(url=url, out=f'{CLASS_DIR}')\n",
    "\n",
    "filename = Path(file).name.replace('.zip', '')\n",
    "\n",
    "!unzip -q -o -d $CLASS_DIR $file \n",
    "!rm $file\n",
    "\n",
    "class_path = class_path.joinpath(filename)\n",
    "CLASS_DIR = class_path.as_posix()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading your personal images, You have 2 options:\n",
    "- Add Google Drive URL that contains your images in the url variable and run the cell.\n",
    "- Upload them directly in \"instance_images\" directory and don't run the cell.\n",
    "- Make sure all images are in PNG format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "instances_path = Path('./instance_images')\n",
    "if not instances_path.exists():\n",
    "    instances_path.mkdir(parents=True)\n",
    "\n",
    "INSTANCE_DIR = instances_path.as_posix()\n",
    "\n",
    "url = \"\"\n",
    "\n",
    "gdown.download_folder(url, quiet=True, use_cookies=False, output=INSTANCE_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming all images to the given instance token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(os.listdir(INSTANCE_DIR)):\n",
    "        os.rename(instances_path.joinpath(img).as_posix(), \n",
    "                        instances_path.joinpath(f'{INSTANCE_TOKEN}-({i}).png').as_posix())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "- Enter the training steps (200) * n_images (eg. if n_images=10 then enter 2000)\n",
    "- Enter the number of class images you want to use while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "TRAINING_STEPS = 4000 # it should be (200 * number of images) you uploaded\n",
    "CLASS_IMAGES_NUM = 200 # the number of class images you want to use in the training\n",
    "SEED = random.randint(1, 999999)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = TRAINING_STEPS // 10\n",
    "!accelerate launch --mixed_precision=\"fp16\" diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    --image_captions_filename \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --class_data_dir=\"$CLASS_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    --seed=$SEED \\\n",
    "    --resolution=512 \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$steps \\\n",
    "    --num_class_images=$CLASS_IMAGES_NUM\n",
    "\n",
    "!accelerate launch --mixed_precision=\"fp16\" diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    --image_captions_filename \\\n",
    "    --train_only_unet \\\n",
    "    --save_starting_step=5000 \\\n",
    "    --save_n_steps=5000 \\\n",
    "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --seed=$SEED \\\n",
    "    --resolution=512 \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=2e-6 \\\n",
    "    --lr_scheduler=\"polynomial\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$TRAINING_STEPS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert trained model to CKPT\n",
    "- After you run this cell you will find your trained model inside \"models\" directory.\n",
    "- Also it will make a copy for the model inside AUTOMATIC1111 so you can use it with the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path('./models')\n",
    "if not ckpt_path.exists():\n",
    "    ckpt_path.mkdir(parents=True)\n",
    "\n",
    "ckpt_path = ckpt_path.joinpath(f'{INSTANCE_TOKEN}.ckpt')\n",
    "CKPT_DIR = ckpt_path.as_posix()\n",
    "\n",
    "!python diffusers/scripts/convert_diffusers_to_original_stable_diffusion.py --model_path $OUTPUT_DIR  --checkpoint_path $CKPT_DIR --half\n",
    "\n",
    "api_ckpt_path = Path(f'../stable-diffusion-webui/models/Stable-diffusion/{INSTANCE_TOKEN}.ckpt')\n",
    "API_CKPT_DIR = api_ckpt_path.as_posix()\n",
    "\n",
    "!cp $CKPT_DIR $API_CKPT_DIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
